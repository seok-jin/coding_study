## 자연어 처리란?
- 우리 말을 컴퓨터에 이해시키기 위한 기술
- 사람의 말을 컴퓨터가 이해하도록 만들어서, 컴퓨터가 우리에게 도움이 되는 일을 수행하도록 하는 것이 목표
- 부드러운 언어
	- 똑같은 의미의 문장도 여러 형태로 표현
	- 문장의 뜻이 애매함
	- 그 의미나 형태가 유연하게 변함
- 검섹 엔진, 기계 번역, 질의응답 시스템, IME(입력기 전환), 문장 자동요약, 감정분석 등에 이용

## 단어의 의미
- 우리 말의 의미는 `단어`로 구성 => 컴퓨터에 단어의 의미를 이해시키는 게 중요
- 단어의 의미를 이해시키는 방법
	- 시소러스(유의어 사전)
	- 통계 기반 기법
	- 추론 기반 기법(word2vec)

*** 

## 시소러스(Thesaurus)
- 사람이 직접 단어의 의미를 정의하는 것
- 유의어 사전
	- 동의어나 유의어가 한 그룹으로 분류
	- car = auto, automobile, machine, motorcar
- 단어 사이의 상하위, 전체와 부분 등 세세한 관계까지 정의
- 단어들의 관계를 `그래프`로 => `단어 네트워크`를 이용하여 컴퓨터에게 단어 사이의 연결 정의

### WordNet
- NLP 분야에서 가장 유명한 시소러스
- `유의어`나 `단어 네트워크` 이용 가능
- 단어 네트워크를 이용하여 단어 사이의 `유사도`를 구할 수 있음

### 시소러스 문제점
- 사람이 수작업으로 레이블링 해야하므로 문제 발생
1. 시대 변화에 대응하기 어렵다.
2. 사람을 쓰는 비용은 크다
3. 단어의 미묘한 차이를 표현할 수 없다.

***

## 통계 기반 기법
- `말뭉치(corpus)`
	- 대량의 텍스트 데이터 (NLP를 위해 수집된 텍스트 데이터)
	- 이 안에 문장들은 사람이 쓴 것 = 자연어에 대한 사람의 지식이 담김
		- 문장을 쓰는 방법, 단어를 선택하는 방법, 단어의 의미 등
- `통계 기반 기법`은 사람의 지식으로 가득한 말뭉치에서 자동으로, 효율적으로 그 핵심을 추출하는 것
- 전처리
	- 텍스트 데이터를 단어로 분할하고, 분할된 단어들을 단어 ID 목록으로 변환
- 단어의 `분산 표현(distributional representation)`
	- 단어를 벡터로 표현 (단어의 의미를 정확하게 표현하기 위함)
	- 단어를 고정 길이의 `밀집 벡터(dense vector)`로 표현 : 대부분의 원소가 0이 아닌 실수인 벡터

### 분포 가설
- __단어의 의미는 주변 단어에서 형성된다__
	- `맥락(context)`이 의미를 형성 (단어 자체에는 의미 X)
		- 맥락 : 주변에 놓인 단어
		- 맥락의 크기(주변 단어 몇개를 포함할 지)는 `윈도우`라고 함
		- ex) 좌우의 각 두 단어씩이 맥락에 해당함 (윈도우 크기 2)

### 동시발생 행렬
- 어떤 단어를 주목했을 때, 그 주변에 어떤 단어가 몇 번 등장했는가 (`통계 기반 기법`)

### 코사인 유사도
- 벡터 사이의 유사도를 측정하는 방법 중 하나
- 벡터를 `정규화`하고 `내적`을 구함
- 두 벡터가 가리키는 방향이 얼마나 비슷한가
- 완전이 같으면 1, 완전히 다르면 -1

### 유사 단어의 랭킹
- 어떤 단어와 비슷한 단어를 `유사도 순`으로 출력
- 정렬은 정렬 후 인덱스를 반환하는 numpy.argsort() 사용

### 상호정보량
- 동시발생 행렬에서 두 단어가 동시에 __발생한 횟수__ 를 나타냄
	- 고빈도 단어가 있을 경우 문제 : ex) the
- 이를 해결하기 위해 `점별 상호정보량(Pointwise Matual Information(PMI))`
	- PMI가 높을수록 관련성이 높음
	- 단독으로 출현하는 횟수를 고려함
- `PPMI(Positive PMI)`
	- log0 되는거 막음(양의 상호정보량)
	- 음수일 때 0으로 취급
	- 단점(문제점)
		- corpus의 어휘 수가 증가함에 따라 각차단어 벡터의 차원 수도 증가함 
		- 원소 대부분이 0임(`희소행렬` 또는 `희소벡터`) 
			- 벡터의 원소 대부분이 중요하지 않음
			- 각 원소의 중요도가 낮음
		- 벡터는 노이즈에 약하고 견고하지 못함
		- __=> `차원 감소`로 해결__

### 차원 감소(dimensionality reduction)
- 벡터의 차원을 줄이는 방법 (중요한 정보는 최대한 유지하면서)
- 데이터의 분포를 고려해 가장 적합한 `축`을 찾아내는 일
- `희소벡터`에서 중요한 축을 찾아내어 더 적은 차원으로 다시 표현시켜서 `밀집벡터`로 만듬
- 차원을 감소시키는 방법
	- `특잇값분해(Singular Value Decomposition(SVD))`
		- 임의의 행렬을 __세 행렬의 곱으로 분해__
		- https://ohyez.tistory.com/12


