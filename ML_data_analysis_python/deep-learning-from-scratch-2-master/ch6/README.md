## RNN의 문제점
- 시계열 데이터의 `장기 의존 관계`를 학습하기 어려움
	- `BPTT`에서 `기울기 소실(vanishing gradients)` or `기울기 폭발(exploding gradients)` 때문
- RNN 특징 : 이전 시각의 `은닉 상태`를 이용함
- 현재 단순한 RNN 계층은 시간을 거슬러 올라갈수록 기울기가 작아지거나(기울기 소실) 혹은 커질 수 있음(기울기 폭발)
	- 기울기 소실 : 기울기가 일정 수준 이하로 작아지면 가중치 매개변수가 갱신X
		- `게이트`가 추가된 RNN이 해결 (`LSTM`, `GRU` 등)
	- 기울기 폭발 : overflow일으킴 => NaN
		- `기울기 클리핑(gradients clipping)`이 해결
- 기울기 소실 또는 기울기 폭발의 원인
	- tanh 미분
		- x가 0으로부터 멀어질수록 기울기가 작아짐 => 기울기가 tanh 노드를 지날때마다 값은 계속 작아진다.
			- tanh 함수를 T번 통과하면 기울기도 T번 반복해서 작아짐
	- Matmul(행렬곱)
		- 행렬 곱셈에서는 역전파시 매번 똑같은 가중치가 사용됨
		- 행렬 Wh를 T번 반복해서 곱했기 때문에 기울기 소실 또는 기울기 폭발 현상이 일어남
		- Wh가 스칼라라면 Wh가 1보다 크면 지수적으로 증가, 1보다 작으면 지수적으로 감소함
		- Wh가 행렬이라면 행렬의 `특잇값(Singular Value)`이 척도가 됨
			- 특잇값 : 데이터가 얼마나 퍼져있는지
			- 특잇값(여러 특잇값 중 최댓값)이 1보다 큰지 여부를 봄

***

## LSTM(Long Short-Term Memory)
- `기억 셀(memory cell)` 도입 : LSTM 전용 기억 메커니즘
	- 데이터를 자기 자신으로만(LSTM 계층 내에서만) 주고받음
	- LSTM 계층 내에서만 완결되고 다른 계층으로 출력 안 함
	- LSTM의 은닉상태 h는 다른 계층(위쪽)으로 출력함
	- ct: 과거로부터 시각 t까지의 모든 정보를 기억함
		- ht = tanh(ct)
- `게이트(gate)`
	- 데이터의 흐름을 제어
	- 열기/닫기, 어느 정도 열지 조절(데이터의 양)
		- 어느 정도 : `열림 상태(openness)`
			- 범위 : 0.0\~1.0 (시그모이드 함수 이용)
	- __'게이트를 얼마나 열까'라는 것도 데이터로부터 자동으로 학습함__
		- 게이트 전용 가중치 매개변수 필요

### output 게이트
- tanh(ct)에 게이트를 적용
- tanh(ct)의 각 원소가 '다음 시각의 은닉 상태에 얼마나 중요한가'를 조정함
- 즉, 은닉 상태 ht의 출력을 담당함
- `시그모이드 함수`(0\~1) : 데이터를 얼마나 통과시킬지를 정하는 비율로 사용
- `tanh`(-1\~1) : 인코딩된 정보의 강약을 표시

### forget 게이트
- `기억 셀`에 '무엇을 잊을까'를 명확하게 지시
- c(t-1)의 기억 중에서 불필요한 기억을 잊게 해주는 게이트

### 새로운 기억 셀
- 새로 기억해야 할 정보를 기억셀에 추가해야 함
- tanh 노드가 계산한 결과가 이전 시각의 기억 셀 c(t-1)에 더해짐
- tanh 노드는 게이트가 아니다. 새로운 정보를 기억 셀에 추가하는 것이 목적임
- 따라서 시그모이드가 아닌 tanh 사용함

### input 게이트
- 새로운 기억이 추가되는 정보로써의 가치가 얼마나 큰지를 판단

### LSTM 기울기의 흐름
- 기억셀의 역전파에서는 `+`와 `x` 노드만 지나게 됨
	- + : 기울기 변화(감소) X
	- x : 행렬 곱이 아닌 `아마다르 곱(원소별 곱)`임
		- 매 시각 다른 게이트 값을 이용해 원소별 곱을 계산함 (RNN에서는 같은 가중치의 행렬곱)
		- 매번 새로운 게이트 값을 이용하므로 곱셈의 효과가 누적되지 않아 기울기 소실이 잃어나기 어려움
		- forget 게이트가 제어함
			- forget 게이트가 '잊어야 한다'고 판단하면 => 기울기가 작아짐
			- forget 게이트가 '잊어서는 안 된다'라고 판단하면 => 기울기가 약화되지 않은 채로 과거 방향으로 전해짐
			- __기억 셀의 기울기가 오래 기억해야 할 정보일 경우 소실 없이 전파__

***

## RNNLM 추가 개선
1. LSTM 계층 다층화
2. `드롭아웃`에 의한 과적합(overfitting) 억제
	- LSTM을 다층화하면 오버피팅이 일어날 수 있음
	- RNN은 피드포워드 신경망보다 오버피팅이 잘 발생함
3. 가중치 공유

### 오버피팅 억제 방법
1. 훈련 데이터 양 늘리기
2. 모델의 복잡도를 줄이기
3. 모델의 복잡도에 페널티를 주는 `정규화(normalization)`
4. `드롭아웃`: 계층 내의 뉴런 몇 개를 무작위로 무시하고 학습함(일종의 정규화)

### 변형 드롭아웃(variational dropout)
- 시간 방향에도 이용할 수 있는 드롭아웃
- 같은 계층에 속한 드롭아웃들은 같은 마스크를 공유함
	- 마스크 : 데이터의 통과/차단을 결정하는 이진 형태의 무작위 패턴
- 그 결과 정보를 잃게 되는 방법도 고정됨 => 일반적인 드롭아웃과 달리 정보가 지수적으로 손실되는 사태를 피함

### 가중치 공유(weight tying)
- 언어 모델을 개선하는 트릭중 하나
- 두 계층이 가중치를 공유함으로써 학습하는 매개변수 수가 크게 줄어듬 => 학습하기 쉬워지고 오버피팅 억제됨 => 정확도 향상

