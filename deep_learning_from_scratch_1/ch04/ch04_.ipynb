{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y,t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1,t.size)\n",
    "        y = y.reshape(1,y.size)\n",
    "    \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arnge(batch_size),t]+ 1e-7))/ batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "return arrays must be of ArrayType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\OneDrive\\code\\coding_study\\deep_learning_from_scratch_1\\ch04\\ch04_.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000004?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39;49mlog(\u001b[39m0\u001b[39;49m,\u001b[39m2\u001b[39;49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: return arrays must be of ArrayType"
     ]
    }
   ],
   "source": [
    "np.log(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_diff(f,x):\n",
    "    h = 1e-4\n",
    "    return (f(x+h)-f(x-h)) / (2*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def function_1(x):\n",
    "    return 0.01*x**2 + 0.1*x\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "x = np.arange(0.0, 20.0, 0.1) \n",
    "y = function_1(x)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.plot(x,y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1999999999990898\n",
      "0.2999999999986347\n"
     ]
    }
   ],
   "source": [
    "print(numerical_diff(function_1,5))\n",
    "print(numerical_diff(function_1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return np.sum(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f,x):\n",
    "    h = 1e-4 #0.0001\n",
    "    grad = np.zeros_like(x) # x 와 동일한 형상의 배열 생성\n",
    "\n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = tmp_val+h\n",
    "        fxh1 = f(x)\n",
    "\n",
    "        x[idx] = tmp_val-h\n",
    "        fxh2 = f(x)\n",
    "\n",
    "        grad[idx] = (fxh1-fxh2)/(2*h)\n",
    "        x[idx] = tmp_val\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([3.0, 0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.11110793e-10,  8.14814391e-10])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gradient_descent(f,init_x, lr=0.01, stap_num=100):\n",
    "    x = init_x\n",
    "\n",
    "    for i in range(stap_num):\n",
    "        grad = numerical_gradient(f,x)\n",
    "        x -=lr*grad\n",
    "    return x\n",
    "\n",
    "def function_2(x):\n",
    "    return np.sum(x**2)\n",
    "\n",
    "init_x = np.array([-3.0,4.0])\n",
    "gradient_descent(function_2, init_x=init_x,lr=0.1,stap_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np \n",
    "from common.functions import softmax, cross_entropy_error\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2,3)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        z =self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y,t)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.94646003 -1.63008243  0.85545117]\n",
      " [ 0.41685187  0.7834528   0.06720431]]\n"
     ]
    }
   ],
   "source": [
    "net = simpleNet()\n",
    "print(net.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.79270934 -0.27294194  0.57375458]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([0.6,0.9])\n",
    "p = net.predict(x)\n",
    "print(p)\n",
    "np.argmax(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.521074543690188"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([0,0,1])\n",
    "\n",
    "net.loss(x,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09086645  0.15280434 -0.24367079]\n",
      " [ 0.13629968  0.2292065  -0.36550618]]\n"
     ]
    }
   ],
   "source": [
    "def f(W):\n",
    "    return net.loss(x,t)\n",
    "\n",
    "f = lambda w : net.loss(x,t)\n",
    "\n",
    "dW = numerical_gradient(f, net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os \n",
    "sys.path.append(os.pardir)\n",
    "from common.functions import * \n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size,hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "\n",
    "        a1 = np.dot(x, W1) + b1 \n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1 , W2) + b2\n",
    "        y  = softmax(a2)\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def loss(self,x,t):\n",
    "        y = self.predict(x)\n",
    "\n",
    "        return cross_entropy_error(y,t)\n",
    "\n",
    "    def accuracy(self, x, y):\n",
    "        y = self.predict(x)\n",
    "        y= np.argmax(y,axis=1)\n",
    "        t= np.argmax(t,axis=1)\n",
    "\n",
    "        accuracy = np.sum(y==t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_w = lambda W : self.loss(x,t)\n",
    "\n",
    "        grads = {}\n",
    "        grads['W1'] =numerical_gradient(loss_w, self.params['W1'])\n",
    "        grads['b1'] =numerical_gradient(loss_w, self.params['b1'])\n",
    "        grads['W2'] =numerical_gradient(loss_w, self.params['W2'])\n",
    "        grads['b2'] =numerical_gradient(loss_w, self.params['b2'])\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "    \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        grads = {}\n",
    "        \n",
    "        batch_num = x.shape[0]\n",
    "        \n",
    "        # forward\n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        # backward\n",
    "        dy = (y - t) / batch_num\n",
    "        grads['W2'] = np.dot(z1.T, dy)\n",
    "        grads['b2'] = np.sum(dy, axis=0)\n",
    "        \n",
    "        da1 = np.dot(dy, W2.T)\n",
    "        dz1 = sigmoid_grad(a1) * da1\n",
    "        grads['W1'] = np.dot(x.T, dz1)\n",
    "        grads['b1'] = np.sum(dz1, axis=0)\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\OneDrive\\code\\coding_study\\deep_learning_from_scratch_1\\ch04\\ch04_.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000019?line=20'>21</a>\u001b[0m x_batch \u001b[39m=\u001b[39m x_train[batch_mask]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000019?line=21'>22</a>\u001b[0m t_batch \u001b[39m=\u001b[39m t_train[batch_mask]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000019?line=23'>24</a>\u001b[0m grad \u001b[39m=\u001b[39m network\u001b[39m.\u001b[39;49mnumerical_gradient(x_batch,t_batch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000019?line=25'>26</a>\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mW1\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mb1\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mW2\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mb2\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000019?line=26'>27</a>\u001b[0m     network\u001b[39m.\u001b[39mparams[key] \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m learning_rate \u001b[39m*\u001b[39m grad[key]\n",
      "\u001b[1;32md:\\OneDrive\\code\\coding_study\\deep_learning_from_scratch_1\\ch04\\ch04_.ipynb Cell 17'\u001b[0m in \u001b[0;36mTwoLayerNet.numerical_gradient\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000018?line=38'>39</a>\u001b[0m loss_w \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m W : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(x,t)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000018?line=40'>41</a>\u001b[0m grads \u001b[39m=\u001b[39m {}\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000018?line=41'>42</a>\u001b[0m grads[\u001b[39m'\u001b[39m\u001b[39mW1\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39mnumerical_gradient(loss_w, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mW1\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000018?line=42'>43</a>\u001b[0m grads[\u001b[39m'\u001b[39m\u001b[39mb1\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39mnumerical_gradient(loss_w, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mb1\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000018?line=43'>44</a>\u001b[0m grads[\u001b[39m'\u001b[39m\u001b[39mW2\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39mnumerical_gradient(loss_w, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mW2\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32md:\\OneDrive\\code\\coding_study\\deep_learning_from_scratch_1\\ch04\\..\\common\\gradient.py:43\u001b[0m, in \u001b[0;36mnumerical_gradient\u001b[1;34m(f, x)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/../common/gradient.py?line=40'>41</a>\u001b[0m tmp_val \u001b[39m=\u001b[39m x[idx]\n\u001b[0;32m     <a href='file:///d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/../common/gradient.py?line=41'>42</a>\u001b[0m x[idx] \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(tmp_val) \u001b[39m+\u001b[39m h\n\u001b[1;32m---> <a href='file:///d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/../common/gradient.py?line=42'>43</a>\u001b[0m fxh1 \u001b[39m=\u001b[39m f(x) \u001b[39m# f(x+h)\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/../common/gradient.py?line=44'>45</a>\u001b[0m x[idx] \u001b[39m=\u001b[39m tmp_val \u001b[39m-\u001b[39m h \n\u001b[0;32m     <a href='file:///d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/../common/gradient.py?line=45'>46</a>\u001b[0m fxh2 \u001b[39m=\u001b[39m f(x) \u001b[39m# f(x-h)\u001b[39;00m\n",
      "\u001b[1;32md:\\OneDrive\\code\\coding_study\\deep_learning_from_scratch_1\\ch04\\ch04_.ipynb Cell 17'\u001b[0m in \u001b[0;36mTwoLayerNet.numerical_gradient.<locals>.<lambda>\u001b[1;34m(W)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000018?line=37'>38</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnumerical_gradient\u001b[39m(\u001b[39mself\u001b[39m, x, t):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000018?line=38'>39</a>\u001b[0m     loss_w \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m W : \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss(x,t)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000018?line=40'>41</a>\u001b[0m     grads \u001b[39m=\u001b[39m {}\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000018?line=41'>42</a>\u001b[0m     grads[\u001b[39m'\u001b[39m\u001b[39mW1\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39mnumerical_gradient(loss_w, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mW1\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;32md:\\OneDrive\\code\\coding_study\\deep_learning_from_scratch_1\\ch04\\ch04_.ipynb Cell 17'\u001b[0m in \u001b[0;36mTwoLayerNet.loss\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000018?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss\u001b[39m(\u001b[39mself\u001b[39m,x,t):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000018?line=25'>26</a>\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000018?line=27'>28</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m cross_entropy_error(y,t)\n",
      "\u001b[1;32md:\\OneDrive\\code\\coding_study\\deep_learning_from_scratch_1\\ch04\\ch04_.ipynb Cell 17'\u001b[0m in \u001b[0;36mTwoLayerNet.predict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000018?line=14'>15</a>\u001b[0m W1, W2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mW1\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mW2\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000018?line=15'>16</a>\u001b[0m b1, b2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mb1\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mb2\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000018?line=17'>18</a>\u001b[0m a1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(x, W1) \u001b[39m+\u001b[39m b1 \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000018?line=18'>19</a>\u001b[0m z1 \u001b[39m=\u001b[39m sigmoid(a1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/code/coding_study/deep_learning_from_scratch_1/ch04/ch04_.ipynb#ch0000018?line=19'>20</a>\u001b[0m a2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(z1 , W2) \u001b[39m+\u001b[39m b2\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys, os \n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np \n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list = []\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    grad = network.numerical_gradient(x_batch,t_batch)\n",
    "\n",
    "    for key in ('W1','b1','W2','b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "\n",
    "    loss = network.loss(x_batch,t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    # if i%100 == 0:\n",
    "    print('count  '+ i )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.10453333333333334, 0.1029\n",
      "train acc, test acc | 0.7915166666666666, 0.7947\n",
      "train acc, test acc | 0.8714833333333334, 0.8763\n",
      "train acc, test acc | 0.8980166666666667, 0.9015\n",
      "train acc, test acc | 0.90785, 0.9089\n",
      "train acc, test acc | 0.9146, 0.9162\n",
      "train acc, test acc | 0.9189833333333334, 0.9213\n",
      "train acc, test acc | 0.9229333333333334, 0.9255\n",
      "train acc, test acc | 0.9272, 0.9294\n",
      "train acc, test acc | 0.9310666666666667, 0.9334\n",
      "train acc, test acc | 0.9340666666666667, 0.9343\n",
      "train acc, test acc | 0.9360833333333334, 0.9362\n",
      "train acc, test acc | 0.9391166666666667, 0.9388\n",
      "train acc, test acc | 0.9410333333333334, 0.9396\n",
      "train acc, test acc | 0.94415, 0.9427\n",
      "train acc, test acc | 0.9454833333333333, 0.9446\n",
      "train acc, test acc | 0.94745, 0.946\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "# 하이퍼파라미터\n",
    "iters_num = 10000  # 반복 횟수를 적절히 설정한다.\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100   # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 1에폭당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "863e562a23091b64ea909bdd39ad5c680ae68eee289185d8768823e5e1ddc25b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
